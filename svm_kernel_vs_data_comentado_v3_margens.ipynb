{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9295d91",
   "metadata": {},
   "source": [
    "# SVM — Kernels × Datasets (com prints e comentários)\n",
    "\n",
    "Este notebook compara **SVC (C)** e **NuSVC (nu)** com três *kernels* (`linear`, `poly` grau 2, `rbf`)\n",
    "em **três datasets**: linearmente separável, círculos concêntricos (quadrático) e moons (RBF).\n",
    "Inclui comentários passo a passo, **prints** das métricas logo após cada avaliação,\n",
    "e gráficos de **fronteira de decisão** e **matriz de confusão**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Importação das bibliotecas do scikit-learn\n",
    "from sklearn.datasets import make_classification, make_circles, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 2) Geração dos datasets\n",
    "def build_linear(n=600, random_state=7):\n",
    "    X, y = make_classification(n_samples=n, n_features=2, n_informative=2, n_redundant=0,\n",
    "                               n_clusters_per_class=1, class_sep=2.0, flip_y=0.01, random_state=random_state)\n",
    "    return X, y\n",
    "\n",
    "def build_poly(n=600, random_state=7):\n",
    "    X, y = make_circles(n_samples=n, factor=0.45, noise=0.08, random_state=random_state)\n",
    "    return X, y\n",
    "\n",
    "def build_rbf(n=600, random_state=7):\n",
    "    X, y = make_moons(n_samples=n, noise=0.15, random_state=random_state)\n",
    "    return X, y\n",
    "\n",
    "datasets = {\n",
    "    \"linear\": build_linear(),\n",
    "    \"polynomial (circles)\": build_poly(),\n",
    "    \"rbf (moons)\": build_rbf()\n",
    "}\n",
    "\n",
    "# 3) Split treino/teste + padronização\n",
    "def split_scale(X, y, test_size=0.3, seed=37):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=seed)\n",
    "    sc = StandardScaler()\n",
    "    X_train_s = sc.fit_transform(X_train)\n",
    "    X_test_s = sc.transform(X_test)\n",
    "    return X_train_s, X_test_s, y_train, y_test\n",
    "\n",
    "# 4) Avaliação SVC (C) e NuSVC (nu)\n",
    "def eval_models(X_train, X_test, y_train, y_test, C=1.0, nu=0.3, degree=2, gamma=\"scale\"):\n",
    "    results = []\n",
    "    models = {}\n",
    "    cfgs = [\n",
    "        (\"SVC\", \"linear\", dict(kernel=\"linear\", C=C)),\n",
    "        (\"SVC\", \"poly\",   dict(kernel=\"poly\", degree=degree, C=C, gamma=gamma)),\n",
    "        (\"SVC\", \"rbf\",    dict(kernel=\"rbf\", C=C, gamma=gamma)),\n",
    "        (\"NuSVC\", \"linear\", dict(kernel=\"linear\", nu=nu)),\n",
    "        (\"NuSVC\", \"poly\",   dict(kernel=\"poly\", degree=degree, nu=nu, gamma=gamma)),\n",
    "        (\"NuSVC\", \"rbf\",    dict(kernel=\"rbf\", nu=nu, gamma=gamma)),\n",
    "    ]\n",
    "    for kind, kernel, params in cfgs:\n",
    "        if kind == \"SVC\":\n",
    "            clf = SVC(decision_function_shape=\"ovr\", random_state=42, **params)\n",
    "        else:\n",
    "            clf = NuSVC(decision_function_shape=\"ovr\", random_state=42, **params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        results.append({\"model\": kind, \"kernel\": kernel, \"C\": params.get(\"C\"), \"nu\": params.get(\"nu\"),\n",
    "                        \"degree\": params.get(\"degree\"), \"gamma\": params.get(\"gamma\"),\n",
    "                        \"accuracy\": acc, \"balanced_accuracy\": bacc})\n",
    "        models[(kind, kernel)] = (clf, cm, y_pred)\n",
    "    return pd.DataFrame(results), models\n",
    "\n",
    "# 5) Helpers de plot\n",
    "def plot_boundary(model, X_train, X_test, y_test, title):\n",
    "    X_vis = np.vstack([X_train, X_test])\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_vis[:, 0].min() - 0.5, X_vis[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_vis[:, 1].min() - 0.5, X_vis[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.predict(grid).reshape(xx.shape)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=20, edgecolor='k')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1 (scaled)\")\n",
    "    plt.ylabel(\"Feature 2 (scaled)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cm(cm, title):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(values_format='d')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 6) Execução: imprime métricas após cada dataset\n",
    "all_rows = []\n",
    "stored_models = {}\n",
    "for dname, (X, y) in datasets.items():\n",
    "    print(\"=\"*80)\n",
    "    print(f\"DATASET: {dname}\")\n",
    "    Xtr, Xte, ytr, yte = split_scale(X, y)\n",
    "    C_val, nu_val, degree_val, gamma_val = 1.0, 0.3, 2, \"scale\"\n",
    "    print(f\"Hiperparâmetros: C={C_val}, nu={nu_val}, degree={degree_val}, gamma={gamma_val}\")\n",
    "    df_metrics, models = eval_models(Xtr, Xte, ytr, yte, C=C_val, nu=nu_val, degree=degree_val, gamma=gamma_val)\n",
    "    print(df_metrics.round(4).to_string(index=False))\n",
    "    df_metrics.insert(0, \"dataset\", dname)\n",
    "    all_rows.append(df_metrics)\n",
    "    stored_models[dname] = (Xtr, Xte, ytr, yte, models)\n",
    "\n",
    "metrics_all = pd.concat(all_rows, ignore_index=True)\n",
    "metrics_all.round(4)\n",
    "\n",
    "# 7) Plots SVC (3 kernels) por dataset\n",
    "for dname, (Xtr, Xte, ytr, yte, models) in stored_models.items():\n",
    "    for kernel in [\"linear\", \"poly\", \"rbf\"]:\n",
    "        clf, cm, _ = models[(\"SVC\", kernel)]\n",
    "        plot_boundary(clf, Xtr, Xte, yte, f\"{dname} — Fronteira SVC ({kernel})\")\n",
    "        plot_cm(cm, f\"{dname} — Matriz de Confusão SVC ({kernel})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27777b07",
   "metadata": {},
   "source": [
    "\n",
    "## Complemento: margens (±1), fronteira (0) e vetores de suporte (SVC)\n",
    "\n",
    "As células abaixo **não substituem nada do notebook original** — apenas **acrescentam** visualizações:\n",
    "- **Fronteira de decisão** definida por `decision_function = 0`.\n",
    "- **Margens clássicas** nos níveis `decision_function = ±1`.\n",
    "- **Vetores de suporte** marcados com `x` (no espaço escalonado).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_with_margins(model, X_train, X_test, y_test, title):\n",
    "    \"\"\"\n",
    "    Plota regiões de decisão, fronteira (0), margens (±1) e marca vetores de suporte (x).\n",
    "    Usa as duas features (dados já padronizados).\n",
    "    \"\"\"\n",
    "    X_vis = np.vstack([X_train, X_test])\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_vis[:, 0].min() - 0.5, X_vis[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_vis[:, 1].min() - 0.5, X_vis[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # decision_function em toda a grade (necessária para margens/fonteira)\n",
    "    Z = model.decision_function(grid).reshape(xx.shape)\n",
    "    # predição para colorir as regiões\n",
    "    Z_pred = model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    # Regiões de decisão\n",
    "    plt.contourf(xx, yy, Z_pred, alpha=0.25)\n",
    "    # Fronteira (0) e margens (±1)\n",
    "    CS = plt.contour(xx, yy, Z, levels=[-1, 0, 1], linestyles=['--', '-', '--'])\n",
    "    plt.clabel(CS, inline=True, fontsize=8)\n",
    "\n",
    "    # Pontos de teste\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=22, edgecolor='k')\n",
    "\n",
    "    # Vetores de suporte (no espaço escalonado)\n",
    "    if hasattr(model, \"support_vectors_\"):\n",
    "        sv = model.support_vectors_\n",
    "        plt.scatter(sv[:, 0], sv[:, 1], s=60, marker='x')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1 (scaled)\")\n",
    "    plt.ylabel(\"Feature 2 (scaled)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Executa somente se o bloco principal já tiver sido rodado e \"stored_models\" existir\n",
    "try:\n",
    "    _ = stored_models\n",
    "except NameError:\n",
    "    print(\"Nota: execute antes as células que constroem 'stored_models' (seção principal do notebook).\")\n",
    "else:\n",
    "    for dname, (Xtr, Xte, ytr, yte, models) in stored_models.items():\n",
    "        for kernel in [\"linear\", \"poly\", \"rbf\"]:\n",
    "            # Usa SVC treinado previamente\n",
    "            clf, _, _ = models[(\"SVC\", kernel)]\n",
    "            plot_decision_with_margins(clf, Xtr, Xte, yte, f\"{dname} — SVC ({kernel}) com margens e SVs\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
